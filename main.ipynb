{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c369ece8-81bf-44ed-ad52-22d4dc5df0a2",
   "metadata": {},
   "source": [
    "NeurIPS 2023 Tutorial on Machine Learning for Theorem Proving\n",
    "============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1bbb7fd-45d3-4b96-82e1-a03b2ae39f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0db42e7110>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from transformers import (\n",
    "  AutoModelForSeq2SeqLM,\n",
    "  AutoTokenizer,\n",
    "  Seq2SeqTrainer,\n",
    "  Seq2SeqTrainingArguments,\n",
    "  DataCollatorForSeq2Seq,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "# https://arxiv.org/abs/2109.08203\n",
    "random.seed(3407)\n",
    "np.random.seed(3407)\n",
    "torch.manual_seed(3407)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc100ade-be6f-4549-9d65-e5dc1d2e083b",
   "metadata": {},
   "source": [
    "## Roadmap\n",
    "\n",
    "* Goal: Using language models to build a theorem prover in Lean.\n",
    "* Training the tactic generator\n",
    "  * Using [**LeanDojo**](https://github.com/lean-dojo/LeanDojo) to extract data (state-tactic pairs) from mathlib.\n",
    "  * Finetuning a language model for tactic generation\n",
    "* Searching for proofs\n",
    "  * Interacting with Lean using [**LeanDojo**](https://github.com/lean-dojo/LeanDojo)\n",
    "  * Proof search with DFS\n",
    "* Using the model in Lean with [**Lean Copilot**](https://github.com/lean-dojo/LeanInfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a26cdf-9d79-4612-a271-8871b0bc8634",
   "metadata": {},
   "source": [
    "## Data Extraction\n",
    "\n",
    "We use **[LeanDojo](https://leandojo.org/)** to extract state-tactic pairs from mathlib.\n",
    "\n",
    "### Trace the Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0167849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lean_dojo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a1ad05-2ab8-4bc8-b137-c8d602cd0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = LeanGitRepo(\n",
    "    \"https://github.com/leanprover-community/mathlib4\",\n",
    "    \"3ce43c18f614b76e161f911b75a3e1ef641620ff\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd8b02e-be5b-4622-a37c-b762e2becde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-08 18:49:54.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlean_dojo.data_extraction.trace\u001b[0m:\u001b[36mtrace\u001b[0m:\u001b[36m182\u001b[0m - \u001b[1mLoading the traced repo from /home/kaiyu/.cache/lean_dojo/leanprover-community-mathlib4-3ce43c18f614b76e161f911b75a3e1ef641620ff/mathlib4\u001b[0m\n",
      "2023-12-08 18:49:57,134\tINFO worker.py:1664 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "100%|██████████| 4462/4462 [07:40<00:00,  9.69it/s]  \n",
      "Following Github server redirection from /repos/mhuisi/lean4-cli to /repositories/341363356\n"
     ]
    }
   ],
   "source": [
    "traced_repo = trace(repo)  # A few minutes, depending on #CPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae84af8-636f-4859-bbe4-9c37c842d589",
   "metadata": {},
   "source": [
    "### Extract State-Tactic Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1904db12-727c-4540-ab2c-8a4bf36c0a89",
   "metadata": {},
   "source": [
    "`traced_repo` is a data structure containing all data extracted from `repo`. We can post-process it to extract state-tactic pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04d8947-db14-4942-a98c-4a6fde8e3605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103234 theorems/proofs extracted\n"
     ]
    }
   ],
   "source": [
    "theorems = traced_repo.get_traced_theorems()\n",
    "print(f\"{len(theorems)} theorems/proofs extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746da4ce-5a1a-4f42-9d2c-6c1ed72c6e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103234/103234 [00:11<00:00, 9271.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245127 state-tactic pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "state_tactic_pairs = []\n",
    "\n",
    "for thm in tqdm(theorems):\n",
    "  for t in thm.get_traced_tactics():\n",
    "    state_tactic_pairs.append({\n",
    "        \"state\": t.state_before, \n",
    "        \"tactic\": t.tactic\n",
    "    })\n",
    "\n",
    "print(f\"{len(state_tactic_pairs)} state-tactic pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6abbcf-c27d-4d6f-b93c-0f4a67954564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "α : Type u_1\n",
      "β : Type u_2\n",
      "ks : Array α\n",
      "vs : Array β\n",
      "h : Array.size ks = Array.size vs\n",
      "i : Fin (Array.size ks)\n",
      "j : Fin (Array.size vs)\n",
      "k : α\n",
      "v : β\n",
      "⊢ Array.size (Array.set ks i k) = Array.size (Array.set vs j v)\n"
     ]
    }
   ],
   "source": [
    "st = state_tactic_pairs[0]\n",
    "print(st[\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fe04565-4809-4494-8f02-59711f8b1279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simp [h]\n"
     ]
    }
   ],
   "source": [
    "print(st[\"tactic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99349c6-a622-46b8-a452-1707f7280967",
   "metadata": {},
   "source": [
    "## Finetuning Language Models for Tactic Generation\n",
    "\n",
    "There are many excellent libraries that can be used for finetuning tactic generators (e.g., [Pytorch Lightning](https://lightning.ai/), [ReProver](https://github.com/lean-dojo/ReProver)). The code below is only an illustration of the process. DO NOT USE IT FOR PRODUCTION.\n",
    "\n",
    "We finetune a [ByT5](https://arxiv.org/abs/2105.13626) model. It is a tokenization-free version of T5, with the same encoder-decoder Transformer architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b08ea8c2-ee02-4cd5-ac6b-f286c61720f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/byt5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9940c1-6184-46db-a290-7bf89d09fc06",
   "metadata": {},
   "source": [
    "Let's pick a random subset of the data and look at one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a23de4c1-8fc2-4e16-99fb-ca19819e4147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': 'case pos\\n'\n",
      "          'Ω : Type u_1\\n'\n",
      "          'β : Type u_2\\n'\n",
      "          'ι : Type u_3\\n'\n",
      "          'm : MeasurableSpace Ω\\n'\n",
      "          'inst✝ : Preorder ι\\n'\n",
      "          'f : Filtration ι m\\n'\n",
      "          'τ π : Ω → ι\\n'\n",
      "          'hτ : IsStoppingTime f τ\\n'\n",
      "          's : Set Ω\\n'\n",
      "          'i : ι\\n'\n",
      "          'this : ∀ (j : ι), {ω | τ ω = i} ∩ {ω | τ ω ≤ j} = {ω | τ ω = i} ∩ '\n",
      "          '{_ω | i ≤ j}\\n'\n",
      "          'h : MeasurableSet (s ∩ {ω | τ ω = i})\\n'\n",
      "          'j : ι\\n'\n",
      "          'hij : i ≤ j\\n'\n",
      "          '⊢ MeasurableSet (s ∩ ({ω | τ ω = i} ∩ {_ω | i ≤ j}))',\n",
      " 'tactic': 'simp only [hij, Set.setOf_true, Set.inter_univ]'}\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_list(state_tactic_pairs).shuffle().select(range(10000))\n",
    "pprint(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a5ee8d2-aa3d-4f83-8ef9-ca0e28f733e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20f600f4277349febc0d1899429e706e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': 'case pos\\nΩ : Type u_1\\nβ : Type u_2\\nι : Type u_3\\nm : MeasurableSpace Ω\\ninst✝ : Preorder ι\\nf : Filtration ι m\\nτ π : Ω → ι\\nhτ : IsStoppingTime f τ\\ns : Set Ω\\ni : ι\\nthis : ∀ (j : ι), {ω | τ ω = i} ∩ {ω | τ ω ≤ j} = {ω | τ ω = i} ∩ {_ω | i ≤ j}\\nh : MeasurableSet (s ∩ {ω | τ ω = i})\\nj : ι\\nhij : i ≤ j\\n⊢ MeasurableSet (s ∩ ({ω | τ ω = i} ∩ {_ω | i ≤ j}))', 'tactic': 'simp only [hij, Set.setOf_true, Set.inter_univ]', 'input_ids': [102, 100, 118, 104, 35, 115, 114, 118, 13, 209, 172, 35, 61, 35, 87, 124, 115, 104, 35, 120, 98, 52, 13, 209, 181, 35, 61, 35, 87, 124, 115, 104, 35, 120, 98, 53, 13, 209, 188, 35, 61, 35, 87, 124, 115, 104, 35, 120, 98, 54, 13, 112, 35, 61, 35, 80, 104, 100, 118, 120, 117, 100, 101, 111, 104, 86, 115, 100, 102, 104, 35, 209, 172, 13, 108, 113, 118, 119, 229, 159, 160, 35, 61, 35, 83, 117, 104, 114, 117, 103, 104, 117, 35, 209, 188, 13, 105, 35, 61, 35, 73, 108, 111, 119, 117, 100, 119, 108, 114, 113, 35, 209, 188, 35, 112, 13, 210, 135, 35, 210, 131, 35, 61, 35, 209, 172, 35, 229, 137, 149, 35, 209, 188, 13, 107, 210, 135, 35, 61, 35, 76, 118, 86, 119, 114, 115, 115, 108, 113, 106, 87, 108, 112, 104, 35, 105, 35, 210, 135, 13, 118, 35, 61, 35, 86, 104, 119, 35, 209, 172, 13, 108, 35, 61, 35, 209, 188, 13, 119, 107, 108, 118, 35, 61, 35, 229, 139, 131, 35, 43, 109, 35, 61, 35, 209, 188, 44, 47, 35, 126, 210, 140, 35, 127, 35, 210, 135, 35, 210, 140, 35, 64, 35, 108, 128, 35, 229, 139, 172, 35, 126, 210, 140, 35, 127, 35, 210, 135, 35, 210, 140, 35, 229, 140, 167, 35, 109, 128, 35, 64, 35, 126, 210, 140, 35, 127, 35, 210, 135, 35, 210, 140, 35, 64, 35, 108, 128, 35, 229, 139, 172, 35, 126, 98, 210, 140, 35, 127, 35, 108, 35, 229, 140, 167, 35, 109, 128, 13, 107, 35, 61, 35, 80, 104, 100, 118, 120, 117, 100, 101, 111, 104, 86, 104, 119, 35, 43, 118, 35, 229, 139, 172, 35, 126, 210, 140, 35, 127, 35, 210, 135, 35, 210, 140, 35, 64, 35, 108, 128, 44, 13, 109, 35, 61, 35, 209, 188, 13, 107, 108, 109, 35, 61, 35, 108, 35, 229, 140, 167, 35, 109, 13, 229, 141, 165, 35, 80, 104, 100, 118, 120, 117, 100, 101, 111, 104, 86, 104, 119, 35, 43, 118, 35, 229, 139, 172, 35, 43, 126, 210, 140, 35, 127, 35, 210, 135, 35, 210, 140, 35, 64, 35, 108, 128, 35, 229, 139, 172, 35, 126, 98, 210, 140, 35, 127, 35, 108, 35, 229, 140, 167, 35, 109, 128, 44, 44, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [118, 108, 112, 115, 35, 114, 113, 111, 124, 35, 94, 107, 108, 109, 47, 35, 86, 104, 119, 49, 118, 104, 119, 82, 105, 98, 119, 117, 120, 104, 47, 35, 86, 104, 119, 49, 108, 113, 119, 104, 117, 98, 120, 113, 108, 121, 96, 1]}\n"
     ]
    }
   ],
   "source": [
    "def tokenize(examples):\n",
    "  model_inputs = tokenizer(examples[\"state\"], max_length=2048, truncation=True)\n",
    "  labels = tokenizer(text_target=examples[\"tactic\"], max_length=2048, truncation=True)\n",
    "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "  return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "\n",
    "print(tokenized_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe9d715f-9cda-4e39-abf2-60b758eb0ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:18, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2, training_loss=8.766227722167969, metrics={'train_runtime': 42.3437, 'train_samples_per_second': 0.378, 'train_steps_per_second': 0.047, 'total_flos': 25093347827712.0, 'train_loss': 8.766227722167969, 'epoch': 0.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is just an example. Don't run it.\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "  output_dir=\"./results\",\n",
    "  learning_rate=1e-5,\n",
    "  per_device_train_batch_size=8,\n",
    "  max_steps=2,\n",
    "  use_cpu=True,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "  model=model,\n",
    "  tokenizer=tokenizer,\n",
    "  args=training_args,\n",
    "  train_dataset=tokenized_dataset,\n",
    "  data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866872a-93ed-4bbc-bd08-bc85c7f36149",
   "metadata": {},
   "source": [
    "## Inspecting the Trained Tactic Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e5bd19-9b1c-41c9-b474-71ec03402120",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"kaiyuy/leandojo-lean4-tacgen-byt5-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"kaiyuy/leandojo-lean4-tacgen-byt5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6acc714-f761-482a-bb47-f93e8f592d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_one_tactic(state: str) -> str:\n",
    "  \"\"\"Generate a single tactic.\"\"\"\n",
    "  tokenized_state = tokenizer(state, return_tensors=\"pt\")\n",
    "  tactic_ids = model.generate(tokenized_state.input_ids, max_length=1024)\n",
    "  tactic = tokenizer.decode(tactic_ids[0], skip_special_tokens=True)\n",
    "  print(tactic, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3a2c201-db9f-485c-852e-665ae9c71801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intro a b c\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_one_tactic(\"∀ (a b c : ℕ), a + b + c = a + c + b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03109d35-9f7d-4550-88a8-8cb027d403a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tactics(state: str, k: int = 8) -> List[str]:\n",
    "  \"\"\"Generate multiple tactics via beam search.\"\"\"\n",
    "  tokenized_state = tokenizer(state, return_tensors=\"pt\")\n",
    "  tactic_candidates_ids = model.generate(\n",
    "    tokenized_state.input_ids,\n",
    "    max_length=256,\n",
    "    num_beams=k,\n",
    "    length_penalty=0.0,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=k,\n",
    "    early_stopping=False,\n",
    "  )\n",
    "  tactic_candidates = tokenizer.batch_decode(\n",
    "    tactic_candidates_ids, skip_special_tokens=True\n",
    "  )\n",
    "  return tactic_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e8cedd4-7098-42ef-a131-d4b300dfca2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rw [gcd_comm]\n",
      "induction' n with n IH\n",
      "induction' n with n hn\n",
      "cases n\n",
      "rw [gcd]\n",
      "induction' n with n ih\n",
      "unfold gcd\n",
      "rw [gcd_comm, gcd_gcd_self_right]\n"
     ]
    }
   ],
   "source": [
    "for tac in generate_tactics(\"n : ℕ\\n⊢ gcd n n = n\"):\n",
    "  print(tac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb46b438-802d-41a1-86f8-03610b175411",
   "metadata": {},
   "source": [
    "## Interacting with Lean\n",
    "\n",
    "[**LeanDojo**](https://github.com/lean-dojo/LeanDojo) supports interacting with Lean in Python. We'll use the `gcd_self` theorem as an example.\n",
    "\n",
    "![add_abc.jpg](./add_abc.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cec246a-5e70-48e3-8f7d-861e5095280b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-08 06:56:55.792\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mlean_dojo.interaction.dojo\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m172\u001b[0m - \u001b[33m\u001b[1mUsing Lean 4 without a hard timeout may hang indefinitely.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "repo = LeanGitRepo(\n",
    "    \"https://github.com/yangky11/lean4-example\",\n",
    "    \"5117c1d326f0505bef137c7c99099f3f780624b9\",\n",
    ")\n",
    "theorem = Theorem(repo, \"Lean4Example.lean\", \"add_abc\")\n",
    "\n",
    "dojo, s0 = Dojo(theorem).__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7472faca-0ff2-4874-9063-af7754f0d9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n : ℕ\n",
      "⊢ gcd n n = n\n"
     ]
    }
   ],
   "source": [
    "print(s0.pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d64607ab-a74b-4f11-9efb-bcf1521a8487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⊢ ∀ (n : ℕ), gcd n n = n\n"
     ]
    }
   ],
   "source": [
    "s1 = dojo.run_tac(s0, \"revert n\")\n",
    "\n",
    "print(s1.pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a732b232-68ad-4ab9-9177-470e2d14968d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeanError(error='<stdin>:1:1: unknown tactic')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = dojo.run_tac(s1, \"hello world!\")\n",
    "\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "767a5ad5-885e-4c55-89d6-69f5b6d1fd85",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to run a tactic on an invalid state LeanError(error='<stdin>:1:1: unknown tactic').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdojo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_tac\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mskip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LeanDojo/src/lean_dojo/interaction/dojo.py:480\u001b[0m, in \u001b[0;36mDojo.run_tac\u001b[0;34m(self, state, tactic)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_tac\u001b[39m(\u001b[38;5;28mself\u001b[39m, state: TacticState, tactic: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TacticResult:\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(state, TacticState):\n\u001b[0;32m--> 480\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to run a tactic on an invalid state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         )\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tactic, \u001b[38;5;28mstr\u001b[39m), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid tactic \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtactic\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m     tsid \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mid\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to run a tactic on an invalid state LeanError(error='<stdin>:1:1: unknown tactic')."
     ]
    }
   ],
   "source": [
    "dojo.run_tac(s2, \"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba5afbd-5f34-41cc-986e-40c11bd33eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = dojo.run_tac(s0, \"cases n <;> unfold gcd\")\n",
    "\n",
    "print(s3.pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd7bb0-6e11-4ec8-ad67-9e67aac8787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s4 = dojo.run_tac(s3, \"rfl\")\n",
    "\n",
    "print(s4.pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430e4689-df24-4630-a066-6fd4b5d3e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "s5 = dojo.run_tac(s4, \"rw [mod_self]\")\n",
    "\n",
    "print(s5.pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e7b21b-d975-42b1-9a39-ae74d51d32a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s6 = dojo.run_tac(s5, \"simp [gcd]\")\n",
    "\n",
    "s6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e2f933-382a-4ef1-bcd2-e29d3b2c3da7",
   "metadata": {},
   "source": [
    "## Proof Search\n",
    "\n",
    "We combine the tactic generator with Depth First Search (DFS) to search for proofs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e178de-04fd-4614-9c2e-2bab73e8272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tactic = str\n",
    "Proof = List[Tactic]\n",
    "num_candidates = 32\n",
    "depth_limit = 5\n",
    "\n",
    "def dfs(dojo : Dojo, state : TacticState, depth : int) -> Optional[Proof]:\n",
    "    # Check the depth limit.\n",
    "    if depth > depth_limit:\n",
    "        print(\"Hit the depth limit! Backtracking...\")\n",
    "        return None\n",
    "\n",
    "    # Generate tactic candidates.\n",
    "    print(f\"Current goal:\\n{state.pp}\\n\")\n",
    "    print(\"Generating tactics...\")\n",
    "    tactics = generate_tactics(state.pp, num_candidates)\n",
    "    print(f\"{num_candidates} tactic candidates:\")\n",
    "    print(\"\\n\".join(tactics) + \"\\n\")\n",
    "\n",
    "    # Running the generated tactics.\n",
    "    for tac in tactics:\n",
    "        next_state = dojo.run_tac(state, tac)\n",
    "        if isinstance(next_state, ProofFinished):\n",
    "            # Success!\n",
    "            print(\"Found a proof!\")\n",
    "            return [tac]\n",
    "        elif isinstance(next_state, LeanError):\n",
    "            pass\n",
    "        else:\n",
    "            # Call `dfs` recursively.\n",
    "            assert isinstance(next_state, TacticState)\n",
    "            print(f\"Applied tactic: {tac}\\n\")\n",
    "            subproof = dfs(dojo, next_state, depth + 1)\n",
    "            if subproof is not None:\n",
    "                return [tac] + subproof\n",
    "    \n",
    "    print(\"Unable to prove the current goal. Backtracking...\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def search(thm : Theorem) -> Optional[Proof]:\n",
    "    with Dojo(theorem) as (dojo, s0):\n",
    "        return dfs(dojo, s0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0801b0bd-9a7e-4ed0-88b4-15d2778e952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(theorem.full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b2384-54ca-4e50-acc2-ad124e5e2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "proof = search(theorem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1dbb8-0652-458d-93e9-1ccceeca5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\".join(proof))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7accca-8a4e-4c1f-b6b0-8946582bd8ea",
   "metadata": {},
   "source": [
    "## Using the Model in Lean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c76461-76f7-4252-a2a1-53a7c15db391",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

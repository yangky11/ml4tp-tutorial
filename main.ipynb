{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c369ece8-81bf-44ed-ad52-22d4dc5df0a2",
   "metadata": {},
   "source": [
    "[NeurIPS 2023 Tutorial on Machine Learning for Theorem Proving](https://github.com/lean-dojo/LeanCopilot)\n",
    "==============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1bbb7fd-45d3-4b96-82e1-a03b2ae39f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3789be7130>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "  AutoModelForSeq2SeqLM,\n",
    "  AutoTokenizer,\n",
    "  Seq2SeqTrainer,\n",
    "  Seq2SeqTrainingArguments,\n",
    "  DataCollatorForSeq2Seq,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from typing import List, Optional\n",
    "\n",
    "# https://arxiv.org/abs/2109.08203\n",
    "random.seed(3407)\n",
    "np.random.seed(3407)\n",
    "torch.manual_seed(3407)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc100ade-be6f-4549-9d65-e5dc1d2e083b",
   "metadata": {},
   "source": [
    "## Roadmap\n",
    "\n",
    "* Training the tactic generator\n",
    "  * Using [**LeanDojo**](https://github.com/lean-dojo/LeanDojo) to extract data (state-tactic pairs) from mathlib.\n",
    "  * Finetuning a language model for tactic generation\n",
    "* Searching for proofs\n",
    "  * Interacting with Lean using [**LeanDojo**](https://github.com/lean-dojo/LeanDojo)\n",
    "  * Proof search with DFS\n",
    "* Using the model in Lean with [**Lean Copilot**](https://github.com/lean-dojo/LeanInfer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a26cdf-9d79-4612-a271-8871b0bc8634",
   "metadata": {},
   "source": [
    "## Data Extraction\n",
    "\n",
    "We use **[LeanDojo](https://leandojo.org/)** to extract state-tactic pairs from mathlib.\n",
    "\n",
    "### Trace the Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0167849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lean_dojo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59a1ad05-2ab8-4bc8-b137-c8d602cd0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = LeanGitRepo(\n",
    "    \"https://github.com/leanprover-community/mathlib4\",\n",
    "    \"3ce43c18f614b76e161f911b75a3e1ef641620ff\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd8b02e-be5b-4622-a37c-b762e2becde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-11 16:57:03.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlean_dojo.data_extraction.trace\u001b[0m:\u001b[36mtrace\u001b[0m:\u001b[36m182\u001b[0m - \u001b[1mLoading the traced repo from /home/kaiyu/.cache/lean_dojo/leanprover-community-mathlib4-3ce43c18f614b76e161f911b75a3e1ef641620ff/mathlib4\u001b[0m\n",
      "2023-12-11 16:57:05,673\tINFO worker.py:1664 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4462/4462 [07:27<00:00,  9.96it/s]  \n",
      "Following Github server redirection from /repos/mhuisi/lean4-cli to /repositories/341363356\n"
     ]
    }
   ],
   "source": [
    "traced_repo = trace(repo)  # A few minutes, depending on #CPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae84af8-636f-4859-bbe4-9c37c842d589",
   "metadata": {},
   "source": [
    "### Extract State-Tactic Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1904db12-727c-4540-ab2c-8a4bf36c0a89",
   "metadata": {},
   "source": [
    "`traced_repo` is a data structure containing all data extracted from `repo`. We can post-process it to extract state-tactic pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04d8947-db14-4942-a98c-4a6fde8e3605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103234 theorems/proofs extracted\n"
     ]
    }
   ],
   "source": [
    "theorems = traced_repo.get_traced_theorems()\n",
    "print(f\"{len(theorems)} theorems/proofs extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746da4ce-5a1a-4f42-9d2c-6c1ed72c6e30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103234/103234 [00:10<00:00, 9775.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245127 state-tactic pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "state_tactic_pairs = []\n",
    "\n",
    "for thm in tqdm(theorems):\n",
    "  for t in thm.get_traced_tactics():\n",
    "    state_tactic_pairs.append({\n",
    "        \"state\": t.state_before, \n",
    "        \"tactic\": t.tactic\n",
    "    })\n",
    "\n",
    "print(f\"{len(state_tactic_pairs)} state-tactic pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6abbcf-c27d-4d6f-b93c-0f4a67954564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Œ± : Type u_1\n",
      "Œ≤ : Type u_2\n",
      "ks : Array Œ±\n",
      "vs : Array Œ≤\n",
      "h : Array.size ks = Array.size vs\n",
      "i : Fin (Array.size ks)\n",
      "j : Fin (Array.size vs)\n",
      "k : Œ±\n",
      "v : Œ≤\n",
      "‚ä¢ Array.size (Array.set ks i k) = Array.size (Array.set vs j v)\n"
     ]
    }
   ],
   "source": [
    "st = state_tactic_pairs[0]\n",
    "print(st[\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fe04565-4809-4494-8f02-59711f8b1279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simp [h]\n"
     ]
    }
   ],
   "source": [
    "print(st[\"tactic\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99349c6-a622-46b8-a452-1707f7280967",
   "metadata": {},
   "source": [
    "## Finetuning Language Models for Tactic Generation\n",
    "\n",
    "There are many excellent libraries that can be used for finetuning tactic generators (e.g., [Pytorch Lightning](https://lightning.ai/), [ReProver](https://github.com/lean-dojo/ReProver)). The code below is only an illustration of the process. DO NOT USE IT FOR PRODUCTION.\n",
    "\n",
    "We finetune a [ByT5](https://arxiv.org/abs/2105.13626) model. It is a tokenization-free version of T5, with the same encoder-decoder Transformer architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b08ea8c2-ee02-4cd5-ac6b-f286c61720f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/byt5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9940c1-6184-46db-a290-7bf89d09fc06",
   "metadata": {},
   "source": [
    "Let's pick a random subset of the data and look at one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a5ee8d2-aa3d-4f83-8ef9-ca0e28f733e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e813ce01e97438bb927aff17530bfef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': 'Œ± : Type u_1\\nŒ≤ : Type u_2\\nŒπ : Type u_3\\nmŒ± : MeasurableSpace Œ±\\nœÅ : Measure (Œ± √ó ‚Ñù)\\ninst‚úù : IsFiniteMeasure œÅ\\n‚ä¢ Tendsto (fun r => ‚à´‚Åª (a : Œ±), preCdf œÅ r a ‚àÇMeasure.fst œÅ) atBot (ùìù 0)', 'tactic': 'convert œÅ.tendsto_IicSnd_atBot MeasurableSet.univ', 'input_ids': [209, 180, 35, 61, 35, 87, 124, 115, 104, 35, 120, 98, 52, 13, 209, 181, 35, 61, 35, 87, 124, 115, 104, 35, 120, 98, 53, 13, 209, 188, 35, 61, 35, 87, 124, 115, 104, 35, 120, 98, 54, 13, 112, 209, 180, 35, 61, 35, 80, 104, 100, 118, 120, 117, 100, 101, 111, 104, 86, 115, 100, 102, 104, 35, 209, 180, 13, 210, 132, 35, 61, 35, 80, 104, 100, 118, 120, 117, 104, 35, 43, 209, 180, 35, 198, 154, 35, 229, 135, 160, 44, 13, 108, 113, 118, 119, 229, 159, 160, 35, 61, 35, 76, 118, 73, 108, 113, 108, 119, 104, 80, 104, 100, 118, 120, 117, 104, 35, 210, 132, 13, 229, 141, 165, 35, 87, 104, 113, 103, 118, 119, 114, 35, 43, 105, 120, 113, 35, 117, 35, 64, 65, 35, 229, 139, 174, 229, 132, 190, 35, 43, 100, 35, 61, 35, 209, 180, 44, 47, 35, 115, 117, 104, 70, 103, 105, 35, 210, 132, 35, 117, 35, 100, 35, 229, 139, 133, 80, 104, 100, 118, 120, 117, 104, 49, 105, 118, 119, 35, 210, 132, 44, 35, 100, 119, 69, 114, 119, 35, 43, 243, 160, 150, 160, 35, 51, 44, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [102, 114, 113, 121, 104, 117, 119, 35, 210, 132, 49, 119, 104, 113, 103, 118, 119, 114, 98, 76, 108, 102, 86, 113, 103, 98, 100, 119, 69, 114, 119, 35, 80, 104, 100, 118, 120, 117, 100, 101, 111, 104, 86, 104, 119, 49, 120, 113, 108, 121, 1]}\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.from_list(state_tactic_pairs).shuffle().select(range(10000))\n",
    "\n",
    "def tokenize(examples):\n",
    "  model_inputs = tokenizer(examples[\"state\"], max_length=2048, truncation=True)\n",
    "  labels = tokenizer(text_target=examples[\"tactic\"], max_length=2048, truncation=True)\n",
    "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "  return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "\n",
    "print(tokenized_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe9d715f-9cda-4e39-abf2-60b758eb0ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:38, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2, training_loss=3.8050713539123535, metrics={'train_runtime': 62.8255, 'train_samples_per_second': 0.255, 'train_steps_per_second': 0.032, 'total_flos': 37510822582272.0, 'train_loss': 3.8050713539123535, 'epoch': 0.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is just an example. Don't run it.\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "  output_dir=\"./results\",\n",
    "  learning_rate=1e-5,\n",
    "  per_device_train_batch_size=8,\n",
    "  max_steps=2,\n",
    "  use_cpu=True,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "  model=model,\n",
    "  tokenizer=tokenizer,\n",
    "  args=training_args,\n",
    "  train_dataset=tokenized_dataset,\n",
    "  data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866872a-93ed-4bbc-bd08-bc85c7f36149",
   "metadata": {},
   "source": [
    "## Inspecting the Tactic Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e5bd19-9b1c-41c9-b474-71ec03402120",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"kaiyuy/leandojo-lean4-tacgen-byt5-small\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"kaiyuy/leandojo-lean4-tacgen-byt5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6acc714-f761-482a-bb47-f93e8f592d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_one_tactic(state: str) -> str:\n",
    "  \"\"\"Generate a single tactic.\"\"\"\n",
    "  tokenized_state = tokenizer(state, return_tensors=\"pt\")\n",
    "  tactic_ids = model.generate(tokenized_state.input_ids, max_length=1024)\n",
    "  tactic = tokenizer.decode(tactic_ids[0], skip_special_tokens=True)\n",
    "  print(tactic, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3a2c201-db9f-485c-852e-665ae9c71801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intro a b c\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_one_tactic(\"‚àÄ (a b c : ‚Ñï), a + b + c = a + c + b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03109d35-9f7d-4550-88a8-8cb027d403a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tactics(state: str, k: int = 16) -> List[str]:\n",
    "  \"\"\"Generate multiple tactics via beam search.\"\"\"\n",
    "  tokenized_state = tokenizer(state, return_tensors=\"pt\")\n",
    "  tactic_candidates_ids = model.generate(\n",
    "    tokenized_state.input_ids,\n",
    "    max_length=256,\n",
    "    num_beams=k,\n",
    "    length_penalty=0.0,\n",
    "    do_sample=False,\n",
    "    num_return_sequences=k,\n",
    "    early_stopping=False,\n",
    "  )\n",
    "  tactic_candidates = tokenizer.batch_decode(\n",
    "    tactic_candidates_ids, skip_special_tokens=True\n",
    "  )\n",
    "  return tactic_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e8cedd4-7098-42ef-a131-d4b300dfca2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intro a b c\n",
      "intros\n",
      "simp\n",
      "intros a b c\n",
      "aesop\n",
      "tauto\n",
      "intro\n",
      "simp [add_assoc]\n",
      "simp [add_comm]\n",
      "constructor\n",
      "apply Nat.forall_congr'\n",
      "exact fun a b c => by simp\n",
      "apply Nat.zero_add\n",
      "apply Nat.zero_le\n",
      "apply fun a b c => intro a b c\n",
      "apply Nat.strongInductionOn\n"
     ]
    }
   ],
   "source": [
    "for tac in generate_tactics(\"‚àÄ (a b c : ‚Ñï), a + b + c = a + c + b\"):\n",
    "  print(tac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb46b438-802d-41a1-86f8-03610b175411",
   "metadata": {},
   "source": [
    "## Interacting with Lean\n",
    "\n",
    "[**LeanDojo**](https://github.com/lean-dojo/LeanDojo) supports interacting with Lean in Python. We'll use the `add_abc` theorem as an example.\n",
    "\n",
    "![add_abc.jpg](./add_abc.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cec246a-5e70-48e3-8f7d-861e5095280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = LeanGitRepo(\n",
    "    \"https://github.com/yangky11/lean4-example\",\n",
    "    \"41f6a6aed00cfb71326dd9d941f7427ee3ae0cb7\",\n",
    ")\n",
    "theorem = Theorem(repo, \"Lean4Example.lean\", \"add_abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "405cfa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-11 17:08:55.535\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mlean_dojo.interaction.dojo\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m172\u001b[0m - \u001b[33m\u001b[1mUsing Lean 4 without a hard timeout may hang indefinitely.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dojo, s0 = Dojo(theorem).__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7472faca-0ff2-4874-9063-af7754f0d9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ä¢ ‚àÄ (a b c : ‚Ñï), a + b + c = a + c + b\n"
     ]
    }
   ],
   "source": [
    "print(s0.pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d64607ab-a74b-4f11-9efb-bcf1521a8487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a b c : ‚Ñï\n",
      "‚ä¢ a + b + c = a + c + b\n"
     ]
    }
   ],
   "source": [
    "s1 = dojo.run_tac(s0, \"intro a b c\")\n",
    "\n",
    "print(s1.pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b11724d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProofFinished(tactic_state_id=2, message='')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dojo.run_tac(s1, \"rw [Nat.add_right_comm]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3604b5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeanError(error=\"tactic 'induction' failed, major premise type is not an inductive type \\n  ?m.142\\nx‚úù : ?m.142\\n‚ä¢ ‚àÄ (a b c : ‚Ñï), a + b + c = a + c + b\")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dojo.run_tac(s0, \"cases n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a732b232-68ad-4ab9-9177-470e2d14968d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeanError(error='<stdin>:1:1: unknown tactic')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dojo.run_tac(s1, \"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e2f933-382a-4ef1-bcd2-e29d3b2c3da7",
   "metadata": {},
   "source": [
    "## Proof Search\n",
    "\n",
    "We combine the tactic generator with Depth First Search (DFS) to search for proofs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1e178de-04fd-4614-9c2e-2bab73e8272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tactic = str\n",
    "Proof = List[Tactic]\n",
    "\n",
    "num_candidates = 16\n",
    "depth_limit = 3\n",
    "\n",
    "def search(state : TacticState, depth : int) -> Optional[Proof]:\n",
    "    \"\"\"Try to prove `state` using depth-first search (DFS).\"\"\"\n",
    "    if depth >= depth_limit:\n",
    "        return None\n",
    "\n",
    "    tactics = generate_tactics(state.pp, num_candidates)\n",
    "\n",
    "    # Run the tactics.\n",
    "    for tac in tactics:\n",
    "        next_state = dojo.run_tac(state, tac)\n",
    "        if isinstance(next_state, ProofFinished):\n",
    "            return [tac]  # Found a proof!\n",
    "        elif not isinstance(next_state, LeanError):\n",
    "            # Call `dfs` recursively.\n",
    "            subproof = search(next_state, depth + 1)\n",
    "            if subproof is not None:\n",
    "                return [tac] + subproof\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f67b2384-54ca-4e50-acc2-ad124e5e2025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a proof!\n",
      "\n",
      "intro a b c\n",
      "rw [Nat.add_right_comm]\n"
     ]
    }
   ],
   "source": [
    "proof = search(s0, depth=0)\n",
    "\n",
    "if proof is not None:\n",
    "    print(\"Found a proof!\\n\")\n",
    "    print(\"\\n\".join(proof))\n",
    "else:\n",
    "    print(\"Failed to find a proof :(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a02c4e",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Use **[LeanDojo](https://github.com/lean-dojo/LeanDojo)** to extract state-tactic pairs from [mathlib](https://github.com/leanprover-community/mathlib4).\n",
    "2. Finetune an encoder-decoder Transformer for tactic generation.\n",
    "3. Combine the tactic generator with search algorithms such as DFS.\n",
    "\n",
    "\n",
    "### Open-Source Tools\n",
    "\n",
    "* [LeanDojo](https://github.com/lean-dojo/LeanDojo)\n",
    "* [ReProver](https://github.com/lean-dojo/ReProver/issues)\n",
    "* [Lean Copilot](https://github.com/lean-dojo/LeanCopilot)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
